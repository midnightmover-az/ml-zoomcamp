{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3322adda-7662-4f60-a4f6-745283f6a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version = 2.1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.inspection.permutation_importance import permutation_importance\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pandas_version = pd.__version__\n",
    "\n",
    "#skipTimEconsumming = True\n",
    "skipTimEconsumming = False\n",
    "\n",
    "print( 'Pandas version = ' + pandas_version + '\\n' )\n",
    "\n",
    "df = pd.read_csv('data-ch06-housing.csv')\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a03c89-88bd-4118-970e-38d265e5215f",
   "metadata": {},
   "source": [
    "First, keep only the records where ocean_proximity is either '<1H OCEAN' or 'INLAND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b014e35-f213-413d-8455-04e5bd206686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19346/1448140692.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['ocean_proximity'] = filtered_df['ocean_proximity'].replace('<1H OCEAN','less 1H OCEAN')\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[ ( df['ocean_proximity'] == '<1H OCEAN' ) | ( df['ocean_proximity'] == 'INLAND' ) ]\n",
    "\n",
    "filtered_df['ocean_proximity'] = filtered_df['ocean_proximity'].replace('<1H OCEAN','less 1H OCEAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3855c50-dd1f-4942-931c-8cbe922319fc",
   "metadata": {},
   "source": [
    "Preparation:\n",
    "\n",
    "    Fill missing values with zeros.\n",
    "    Apply the log transform to median_house_value.\n",
    "    Do train/validation/test split with 60%/20%/20% distribution.\n",
    "    Use the train_test_split function and set the random_state parameter to 1.\n",
    "    Use DictVectorizer(sparse=True) to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38abc254-5dd6-4e14-956c-29ab7d6390b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.fillna(0)\n",
    "\n",
    "seed = 1\n",
    "df_full_train, df_test = train_test_split(filtered_df, test_size=0.2, random_state=seed)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=seed)\n",
    "\n",
    "# Split done \n",
    "\n",
    "y_train_orig = df_train.median_house_value.values\n",
    "y_val_orig = df_val.median_house_value.values\n",
    "y_test_orig = df_test.median_house_value.values\n",
    "\n",
    "y_train = np.log1p(df_train.median_house_value.values)\n",
    "y_val = np.log1p(df_val.median_house_value.values)\n",
    "y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "del df_train['median_house_value']\n",
    "del df_val['median_house_value']\n",
    "del df_test['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b56242-a2fe-489b-a56a-0b9b11dad109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = df_train.to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf6ee11-e56f-4325-b6cc-dd723d770f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=1)\n",
    "#dt = RandomForestRegressor(max_depth=1)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ec71f3-4af2-4e48-aa78-fc4a44408577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    error = y_pred - y\n",
    "    mse = (error ** 2).mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9572f8-bf05-47d6-a382-c395be76acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on TRAIN data %s =>  0.4522449592423713\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = dt.predict(X_train)\n",
    "print(\"RMSE on TRAIN data %s => \", rmse(y_train, y_train_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d219cc3-b8dc-4f11-a5ff-bd303053badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on VALIDATION data %s =>  0.45168599736547244\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = dt.predict(X_val)\n",
    "print(\"RMSE on VALIDATION data %s => \", rmse(y_val, y_val_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb07324-5dcc-4129-a633-6807129bb5ba",
   "metadata": {},
   "source": [
    "Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the median_house_value variable.\n",
    "\n",
    "    Train a model with max_depth=1.\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "    ocean_proximity\n",
    "    total_rooms\n",
    "    latitude\n",
    "    population\n",
    "\n",
    "AMSWER: ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed427d4c-d02d-42fa-91d1-1d68a9596b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['households', 'housing_median_age', 'latitude', 'longitude', 'median_income', 'ocean_proximity=INLAND', 'ocean_proximity=less 1H OCEAN', 'population', 'total_bedrooms', 'total_rooms']\n",
      "|--- ocean_proximity=less 1H OCEAN <= 0.50\n",
      "|   |--- value: [11.61]\n",
      "|--- ocean_proximity=less 1H OCEAN >  0.50\n",
      "|   |--- value: [12.30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureNames=list(dv.get_feature_names_out())\n",
    "print(featureNames)\n",
    "print(export_text(dt, feature_names=featureNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2401ae-9e88-46d8-a8de-0ef7af5ef549",
   "metadata": {},
   "source": [
    "Train a random forest model with these parameters:\n",
    "\n",
    "    n_estimators=10\n",
    "    random_state=1\n",
    "    n_jobs=-1 (optional - to make training faster)\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "    0.045\n",
    "    0.245\n",
    "    0.545\n",
    "    0.845\n",
    "\n",
    "Answer: 0.245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cde00e8-7714-4ff9-8ddf-d0d146bf7f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdaa3ac8-1f79-45f2-8729-3d2c105189d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on TRAIN data %s =>  0.099\n",
      "RMSE on VALIDATION data %s =>  0.245\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = dt.predict(X_train)\n",
    "print(\"RMSE on TRAIN data %s => \", round( rmse(y_train, y_train_pred), 3) )\n",
    "\n",
    "y_val_pred = dt.predict(X_val)\n",
    "print(\"RMSE on VALIDATION data %s => \", round( rmse(y_val, y_val_pred), 3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316a50c-9834-4fe1-965e-4cc1375f6bd7",
   "metadata": {},
   "source": [
    "Question 3\n",
    "\n",
    "Now let's experiment with the n_estimators parameter\n",
    "\n",
    "    Try different values of this parameter from 10 to 200 with step 10.\n",
    "    Set random_state to 1.\n",
    "    Evaluate the model on the validation dataset.\n",
    "\n",
    "After which value of n_estimators does RMSE stop improving? Consider 3 decimal places for retrieving the answer.\n",
    "\n",
    "    10\n",
    "    25\n",
    "    50\n",
    "    160\n",
    "\n",
    "ANSWER: 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f508c15f-3bbf-4447-9ed3-fb118ad0344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators =  10 RMSE on VALIDATION data %s =>  0.245\n",
      "n_estimators =  20 RMSE on VALIDATION data %s =>  0.239\n",
      "n_estimators =  30 RMSE on VALIDATION data %s =>  0.237\n",
      "n_estimators =  40 RMSE on VALIDATION data %s =>  0.235\n",
      "n_estimators =  50 RMSE on VALIDATION data %s =>  0.235\n",
      "n_estimators =  60 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  70 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  80 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  90 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  100 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  110 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  120 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  130 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  140 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  150 RMSE on VALIDATION data %s =>  0.233\n",
      "n_estimators =  160 RMSE on VALIDATION data %s =>  0.233\n",
      "n_estimators =  170 RMSE on VALIDATION data %s =>  0.233\n",
      "n_estimators =  180 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  190 RMSE on VALIDATION data %s =>  0.234\n",
      "n_estimators =  200 RMSE on VALIDATION data %s =>  0.234\n"
     ]
    }
   ],
   "source": [
    "if not skipTimEconsumming:\n",
    "    for n_estimators in range(10,210,10):\n",
    "        dt = RandomForestRegressor(n_estimators=n_estimators, random_state=1, n_jobs=-1)\n",
    "        dt.fit(X_train, y_train)\n",
    "    \n",
    "        y_val_pred = dt.predict(X_val)\n",
    "        print(\"n_estimators = \", n_estimators, \"RMSE on VALIDATION data %s => \", round( rmse(y_val, y_val_pred), 3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624bdaf-d63d-4ad5-85e3-ada3dd7fe862",
   "metadata": {},
   "source": [
    "Question 4\n",
    "\n",
    "Let's select the best max_depth:\n",
    "\n",
    "    Try different values of max_depth: [10, 15, 20, 25]\n",
    "    For each of these values,\n",
    "        try different values of n_estimators from 10 till 200 (with step 10)\n",
    "        calculate the mean RMSE\n",
    "    Fix the random seed: random_state=1\n",
    "\n",
    "What's the best max_depth, using the mean RMSE?\n",
    "\n",
    "    10\n",
    "    15\n",
    "    20\n",
    "    25\n",
    "\n",
    "ANSWER: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2f8b1e-c3ff-49ea-b399-c1cc02318d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth =  10 n_estimators =  10 RMSE on VALIDATION data %s =>  0.251\n",
      "maxDepth =  10 n_estimators =  20 RMSE on VALIDATION data %s =>  0.248\n",
      "maxDepth =  10 n_estimators =  30 RMSE on VALIDATION data %s =>  0.246\n",
      "maxDepth =  10 n_estimators =  40 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  50 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  60 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  70 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  80 RMSE on VALIDATION data %s =>  0.246\n",
      "maxDepth =  10 n_estimators =  90 RMSE on VALIDATION data %s =>  0.246\n",
      "maxDepth =  10 n_estimators =  100 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  110 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  120 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  130 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  140 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  150 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  160 RMSE on VALIDATION data %s =>  0.244\n",
      "maxDepth =  10 n_estimators =  170 RMSE on VALIDATION data %s =>  0.244\n",
      "maxDepth =  10 n_estimators =  180 RMSE on VALIDATION data %s =>  0.244\n",
      "maxDepth =  10 n_estimators =  190 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  10 n_estimators =  200 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  15 n_estimators =  10 RMSE on VALIDATION data %s =>  0.246\n",
      "maxDepth =  15 n_estimators =  20 RMSE on VALIDATION data %s =>  0.239\n",
      "maxDepth =  15 n_estimators =  30 RMSE on VALIDATION data %s =>  0.237\n",
      "maxDepth =  15 n_estimators =  40 RMSE on VALIDATION data %s =>  0.236\n",
      "maxDepth =  15 n_estimators =  50 RMSE on VALIDATION data %s =>  0.236\n",
      "maxDepth =  15 n_estimators =  60 RMSE on VALIDATION data %s =>  0.236\n",
      "maxDepth =  15 n_estimators =  70 RMSE on VALIDATION data %s =>  0.236\n",
      "maxDepth =  15 n_estimators =  80 RMSE on VALIDATION data %s =>  0.236\n",
      "maxDepth =  15 n_estimators =  90 RMSE on VALIDATION data %s =>  0.236\n",
      "maxDepth =  15 n_estimators =  100 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  110 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  120 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  130 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  140 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  150 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  160 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  15 n_estimators =  170 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  15 n_estimators =  180 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  190 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  15 n_estimators =  200 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  10 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  20 n_estimators =  20 RMSE on VALIDATION data %s =>  0.239\n",
      "maxDepth =  20 n_estimators =  30 RMSE on VALIDATION data %s =>  0.237\n",
      "maxDepth =  20 n_estimators =  40 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  50 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  60 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  70 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  80 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  90 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  100 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  110 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  20 n_estimators =  120 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  130 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  140 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  150 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  160 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  170 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  180 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  190 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  20 n_estimators =  200 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  10 RMSE on VALIDATION data %s =>  0.245\n",
      "maxDepth =  25 n_estimators =  20 RMSE on VALIDATION data %s =>  0.239\n",
      "maxDepth =  25 n_estimators =  30 RMSE on VALIDATION data %s =>  0.237\n",
      "maxDepth =  25 n_estimators =  40 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  25 n_estimators =  50 RMSE on VALIDATION data %s =>  0.235\n",
      "maxDepth =  25 n_estimators =  60 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  70 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  80 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  90 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  100 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  110 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  120 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  130 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  140 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  150 RMSE on VALIDATION data %s =>  0.233\n",
      "maxDepth =  25 n_estimators =  160 RMSE on VALIDATION data %s =>  0.233\n",
      "maxDepth =  25 n_estimators =  170 RMSE on VALIDATION data %s =>  0.233\n",
      "maxDepth =  25 n_estimators =  180 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  190 RMSE on VALIDATION data %s =>  0.234\n",
      "maxDepth =  25 n_estimators =  200 RMSE on VALIDATION data %s =>  0.234\n"
     ]
    }
   ],
   "source": [
    "maxDepthList = [10, 15, 20, 25]\n",
    "\n",
    "if not skipTimEconsumming:\n",
    "    for maxDepth in maxDepthList:\n",
    "        for n_estimators in range(10,210,10):\n",
    "            dt = RandomForestRegressor(max_depth=maxDepth, n_estimators=n_estimators, random_state=1, n_jobs=-1)\n",
    "            dt.fit(X_train, y_train)\n",
    "    \n",
    "            y_val_pred = dt.predict(X_val)\n",
    "            print(\"maxDepth = \", maxDepth, \"n_estimators = \", n_estimators, \"RMSE on VALIDATION data %s => \", round( rmse(y_val, y_val_pred), 3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e13acd-6598-47b3-bdc1-e401a0ff6f4c",
   "metadata": {},
   "source": [
    "Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models.\n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "    Train the model with these parameters:\n",
    "        n_estimators=10,\n",
    "        max_depth=20,\n",
    "        random_state=1,\n",
    "        n_jobs=-1 (optional)\n",
    "    Get the feature importance information from this model\n",
    "\n",
    "What's the most important feature (among these 4)?\n",
    "\n",
    "    total_rooms\n",
    "    median_income\n",
    "    total_bedrooms\n",
    "    longitude\n",
    "\n",
    "ANSWER: median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4573fdc-5a9b-41f0-919c-543f1ae8dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_income                    0.335724\n",
      "ocean_proximity=INLAND           0.184371\n",
      "ocean_proximity=less 1H OCEAN    0.181909\n",
      "latitude                         0.102333\n",
      "longitude                        0.085935\n",
      "housing_median_age               0.029955\n",
      "population                       0.027790\n",
      "total_rooms                      0.020913\n",
      "total_bedrooms                   0.016146\n",
      "households                       0.014925\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_val_pred = rf.predict(X_val)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "featureNames = list(dv.get_feature_names_out())\n",
    "\n",
    "forestImportances = pd.Series(importances, index=featureNames)\n",
    "\n",
    "#print( forest_importances )\n",
    "#print (\"\\n\")\n",
    "print( forestImportances.sort_values(ascending=False) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57039a71-35cf-4b0e-b788-ef80b515875f",
   "metadata": {},
   "source": [
    "Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
    "\n",
    "    Install XGBoost\n",
    "    Create DMatrix for train and validation\n",
    "    Create a watchlist\n",
    "    Train a model with these parameters for 100 rounds:\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "Now change eta from 0.3 to 0.1.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "    0.3\n",
    "    0.1\n",
    "    Both give equal value\n",
    "\n",
    "ANSWER: 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cdb8a90-0284-4484-9e95-e37bb5a8acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['households', 'housing_median_age', 'latitude', 'longitude', 'median_income', 'ocean_proximity=INLAND', 'ocean_proximity=less 1H OCEAN', 'population', 'total_bedrooms', 'total_rooms']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = dv.get_feature_names_out().tolist()\n",
    "print( features )\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29dca127-d8aa-443b-a30b-3e887fe17977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for eta = 0.3   0.254\n"
     ]
    }
   ],
   "source": [
    "eta = 0.3\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': eta, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_val_pred = model.predict(dval)\n",
    "\n",
    "print( \"rmse for eta =\", eta, \" \", round( rmse(y_val, y_val_pred), 3) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db69a5a-89a0-4751-9c74-b52a6531aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for eta = 0.1   0.323\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': eta, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_val_pred = model.predict(dval)\n",
    "\n",
    "print( \"rmse for eta =\", eta, \" \", round( rmse(y_val, y_val_pred), 3) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
