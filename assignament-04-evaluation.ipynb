{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f647c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "features = [     \n",
    "    'Make',\n",
    "    'Model',\n",
    "    'Year',\n",
    "    'Engine HP',\n",
    "    'Engine Cylinders',\n",
    "    'Transmission Type',\n",
    "    'Vehicle Style',\n",
    "    'highway MPG',\n",
    "    'city mpg',\n",
    "    'MSRP'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('chapter04-eval-data.csv')\n",
    "df = df[ features ]\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "df = df.fillna(0)\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e280d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priceMean =  40594.737032063116\n"
     ]
    }
   ],
   "source": [
    "priceMean = df['msrp'].mean()\n",
    "print( \"priceMean = \", priceMean)\n",
    "df[ 'above_average' ] = (df['msrp'] > priceMean ) + 0\n",
    "del df['msrp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7414c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=seed)\n",
    "\n",
    "y_train = df_train[ 'above_average' ]\n",
    "y_val = df_val[ 'above_average' ]\n",
    "\n",
    "del df_train[ 'above_average' ]\n",
    "del df_val[ 'above_average' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbd9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and predict functions\n",
    "\n",
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categoricalFeatures + numericalFeatures].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[categoricalFeatures + numericalFeatures].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0a8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalFeatures = [ 'year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg' ]\n",
    "categoricalFeatures = [ 'make', 'model', 'transmission_type', 'vehicle_style' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120c08f",
   "metadata": {},
   "source": [
    "Question 1: ROC AUC feature importance\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "    For each numerical variable, use it as score and compute AUC with the above_average variable\n",
    "    Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. -df_train['engine_hp'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "    engine_hp\n",
    "    engine_cylinders\n",
    "    highway_mpg\n",
    "    city_mpg\n",
    "    \n",
    "ANSWER: engine_hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd34ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature:  year  auc score:  0.5  auc:  0.5\n",
      "Feature:  engine_hp  auc score:  0.7944901528558269  auc:  0.7944901528558269\n",
      "Feature:  engine_cylinders  auc score:  0.6821317811693173  auc:  0.6821317811693173\n",
      "Feature:  highway_mpg  auc score:  0.5  auc:  0.5\n",
      "Feature:  city_mpg  auc score:  0.5012800819252432  auc:  0.5012800819252432\n"
     ]
    }
   ],
   "source": [
    "#dv = DictVectorizer(sparse=False)\n",
    "\n",
    "#train_dict = df_train[categoricalFeatures + numericalFeatures].to_dict(orient='records')\n",
    "#X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "for feature in numericalFeatures:\n",
    "    model = LogisticRegression()\n",
    "    model.fit(df_train[feature].to_frame(), y_train)\n",
    "    y_train_pred = model.predict(df_train[feature].to_frame())\n",
    "    #display( y_train )\n",
    "    #display(y_train_pred )\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    auc_score = roc_auc_score(y_train, y_train_pred)\n",
    "    auc_val = metrics.auc(fpr, tpr)\n",
    "    print( \"Feature: \", feature, \" auc score: \", auc_score, \" auc: \", auc_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d71bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just an experiment\n"
     ]
    }
   ],
   "source": [
    "print( \"Just an experiment\")\n",
    "##for feature in numericalFeatures:\n",
    "    #y_train = df_train[ 'above_average' ]\n",
    "    #y_val = df_val[ 'above_average' ]\n",
    "\n",
    "    #del df_train[ 'above_average' ]\n",
    "    #del df_val[ 'above_average' ]\n",
    "    \n",
    "    ##dv, model = train(df_train[feature].to_frame(), y_train, C=1.0)\n",
    "    #y_train_pred = predict(df_train[feature].to_frame(), dv, model)\n",
    "    \n",
    "    #model = LogisticRegression()\n",
    "    #model.fit(df_train[feature].to_frame(), y_train)\n",
    "    #y_train_pred = model.predict(df_train[feature].to_frame())\n",
    "    #display( y_train )\n",
    "    #display(y_train_pred )\n",
    "    ##fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "    ##auc_score = roc_auc_score(y_train, y_train_pred)\n",
    "    ##auc_val = metrics.auc(fpr, tpr)\n",
    "    ##print( \"Feature: \", feature, \" auc score: \", auc_score, \" auc: \", auc_val )\n",
    "    ##display( df_train[feature].to_frame() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558548d",
   "metadata": {},
   "source": [
    "Question 2: Training the model\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "    0.678\n",
    "    0.779\n",
    "    0.878\n",
    "    0.979\n",
    "    \n",
    "ANSWER: 0.971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc040763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got X_train\n"
     ]
    }
   ],
   "source": [
    "train_dict = df_train[categoricalFeatures + numericalFeatures].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "dv.fit(train_dict)\n",
    "\n",
    "X_train = dv.transform(train_dict)\n",
    "print( \"Got X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cba3c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got X_val\n"
     ]
    }
   ],
   "source": [
    "val_dict = df_val[categoricalFeatures + numericalFeatures].to_dict(orient='records')\n",
    "\n",
    "#dv = DictVectorizer(sparse=False)\n",
    "#dv.fit(val_dict)\n",
    "\n",
    "X_val = dv.transform(val_dict)\n",
    "print( \"Got X_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85a2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score:  0.98\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "#y_val_pred = model.predict(X_val)\n",
    "y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "print( \"auc_score: \", round( auc_score, 3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a966d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Variant using Alexey's functions\n",
    "\n",
    "dv, model = train(df_train, y_train, C=1.0)\n",
    "y_val_pred = predict(df_val, dv, model)\n",
    "\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "print( \"auc_score: \", round( auc_score, 3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205cfff",
   "metadata": {},
   "source": [
    "Question 3: Precision and Recall\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "    Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "    For each threshold, compute precision and recall\n",
    "    Plot them\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "    0.28\n",
    "    0.48\n",
    "    0.68\n",
    "    0.88\n",
    " \n",
    "ANSWER:0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7c061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND crt_c= 0.31  precision= 0.928  recall= 0.928\n",
      "FOUND crt_c= 0.33  precision= 0.929  recall= 0.929\n",
      "FOUND crt_c= 0.38  precision= 0.933  recall= 0.933\n",
      "FOUND crt_c= 0.4  precision= 0.934  recall= 0.934\n",
      "FOUND crt_c= 0.41  precision= 0.934  recall= 0.934\n",
      "FOUND crt_c= 0.42  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.43  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.44  precision= 0.934  recall= 0.934\n",
      "FOUND crt_c= 0.45  precision= 0.93  recall= 0.93\n",
      "FOUND crt_c= 0.49  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.5  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.54  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.56  precision= 0.933  recall= 0.933\n",
      "FOUND crt_c= 0.57  precision= 0.933  recall= 0.933\n",
      "FOUND crt_c= 0.58  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.61  precision= 0.938  recall= 0.938\n",
      "FOUND crt_c= 0.63  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.64  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.65  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.66  precision= 0.938  recall= 0.938\n",
      "FOUND crt_c= 0.67  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.68  precision= 0.937  recall= 0.937\n",
      "FOUND IN LIST  0.68\n",
      "FOUND crt_c= 0.69  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.7  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.72  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.74  precision= 0.938  recall= 0.938\n",
      "FOUND crt_c= 0.75  precision= 0.932  recall= 0.932\n",
      "FOUND crt_c= 0.78  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.81  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.82  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.83  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.87  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.89  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.9  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.91  precision= 0.932  recall= 0.932\n",
      "FOUND crt_c= 0.94  precision= 0.932  recall= 0.932\n",
      "FOUND crt_c= 0.95  precision= 0.937  recall= 0.937\n",
      "FOUND crt_c= 0.96  precision= 0.935  recall= 0.935\n",
      "FOUND crt_c= 0.98  precision= 0.936  recall= 0.936\n",
      "FOUND crt_c= 0.99  precision= 0.938  recall= 0.938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f938e96a070>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "possible_answers = [0.28, 0.48, 0.68, 0.88]\n",
    "precissionList = []\n",
    "recallList = []\n",
    "\n",
    "for crt_c in np.arange(0.01,1.0,0.01):\n",
    "    # avoid the rounding error\n",
    "    crt_c = round(crt_c,2)\n",
    "    model = LogisticRegression(solver='liblinear', C=crt_c, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    round_val = 3\n",
    "    precision = round( precision_score(y_val, y_val_pred, average='weighted'), round_val)\n",
    "    recall = round( recall_score(y_val, y_val_pred, average='weighted'), round_val)\n",
    "    precissionList.append(precision)\n",
    "    recallList.append(recall)\n",
    "    if precision == recall:\n",
    "        print(\"FOUND crt_c=\", crt_c ,\" precision=\", precision, \" recall=\", recall )\n",
    "        if crt_c in possible_answers:\n",
    "            print(\"FOUND IN LIST \", crt_c) \n",
    "    #if precision > recall:\n",
    "    #    print(\" P>R crt_c=\", crt_c ,\" precision=\", precision, \" recall=\", recall )\n",
    "    #else:\n",
    "    #    print(\"P<R crt_c=\", crt_c,\" precision=\", precision, \" recall=\", recall )\n",
    "plt.plot(precissionList, recallList)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800217c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.01  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.02  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.03  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.04  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.05  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.06  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.07  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.08  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.09  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.1  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.11  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.12  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.13  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.14  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.15  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.16  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.17  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.18  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.19  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.2  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.21  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.22  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.23  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.24  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.25  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.26  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.27  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.28  precision= 0.855  recall= 0.855\n",
      "FOUND IN LIST  0.28\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.29  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.3  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.31  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.32  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.33  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.34  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.35  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.36  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.37  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.38  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.39  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.4  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.41  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.42  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.43  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.44  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.45  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.46  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.47  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.48  precision= 0.855  recall= 0.855\n",
      "FOUND IN LIST  0.48\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.49  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.5  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.51  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.52  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.53  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.54  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.55  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.56  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.57  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.58  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.59  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.6  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.61  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.62  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.63  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.64  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.65  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.66  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.67  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.68  precision= 0.855  recall= 0.855\n",
      "FOUND IN LIST  0.68\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.69  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.7  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.71  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.72  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.73  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.74  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.75  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.76  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.77  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.78  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.79  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.8  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.81  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.82  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.83  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.84  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.85  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.86  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.87  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.88  precision= 0.855  recall= 0.855\n",
      "FOUND IN LIST  0.88\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.89  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.9  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.91  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.92  precision= 0.855  recall= 0.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.93  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.94  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.95  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.96  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.97  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.98  precision= 0.855  recall= 0.855\n",
      "0.8549618320610687 0.8615384615384616\n",
      "FOUND crt_c= 0.99  precision= 0.855  recall= 0.855\n",
      "[0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687, 0.8549618320610687]\n",
      "[0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616, 0.8615384615384616]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f938e9bd4c0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variant using Alexey's functions\n",
    "\n",
    "possible_answers = [0.28, 0.48, 0.68, 0.88]\n",
    "\n",
    "precissionList = []\n",
    "recallList = []\n",
    "\n",
    "treshhold = 0.5\n",
    "\n",
    "for crt_c in np.arange(0.01,1.0,0.01):\n",
    "    # avoid the rounding error\n",
    "    crt_c = round(crt_c,2)\n",
    "    \n",
    "    #print(crt_c)\n",
    "    dv, model = train(df_train, y_train, C=crt_c)\n",
    "    y_val_pred = predict(df_val, dv, model)\n",
    "    \n",
    "    #print( y_val_pred)\n",
    "    ###model = LogisticRegression(solver='liblinear', C=crt_c, max_iter=1000)\n",
    "    ###model.fit(X_train, y_train)\n",
    "    ###y_val_pred = model.predict(X_val)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    \n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "\n",
    "    predict_positive = (y_pred >= treshhold)\n",
    "    predict_negative = (y_pred < treshhold)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall =  tp / (tp + fn)\n",
    "    \n",
    "    #precision = precision_score(y_val, y_val_pred >= 0.5, average='weighted')\n",
    "    #recall = recall_score(y_val, y_val_pred >= 0.5, average='weighted')\n",
    "    \n",
    "    precissionList.append(precision)\n",
    "    recallList.append(recall)\n",
    "    \n",
    "    print(precision, recall)\n",
    "    round_val = 3\n",
    "    precision = round( precision, round_val )\n",
    "    recall = round( precision, round_val )\n",
    "    if precision == recall:\n",
    "        print(\"FOUND crt_c=\", crt_c ,\" precision=\", precision, \" recall=\", recall )\n",
    "        if crt_c in possible_answers:\n",
    "            print(\"FOUND IN LIST \", crt_c) \n",
    "    #print( accuracy_score(y_val, y_val_pred >= 0.5) )\n",
    "print(precissionList)\n",
    "print(recallList)\n",
    "\n",
    "plt.plot(precissionList, recallList)\n",
    "#print(\"Done this step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf2191",
   "metadata": {},
   "source": [
    "Question 4: F1 score\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "        \n",
    "        F1 = 2 * P * R/ (P + R)\n",
    "\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "    0.12\n",
    "    0.32\n",
    "    0.52\n",
    "    0.72\n",
    "\n",
    "ANSWER: 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a35b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_answers = [0.12, 0.32, 0.52, 0.72]\n",
    "maxF1 = 0\n",
    "cForMaxF = 0\n",
    "treshhold = 0.5\n",
    "for crt_c in np.arange(0.01,1.0,0.01):\n",
    "    # avoid the rounding error\n",
    "    crt_c = round(crt_c,2) + 0.0\n",
    "    model = LogisticRegression(solver='liblinear', C=crt_c, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    #y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    #fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred  >= treshhold, average='weighted')\n",
    "    recall = recall_score(y_val, y_val_pred  >= treshhold, average='weighted')\n",
    "    round_val = 6\n",
    "    #precision = round( precision, round_val)\n",
    "    #recall = round( recall, round_val)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    if F1 >= maxF1:\n",
    "        #print( \"Found new max F1; maxF1=\", F1, \" cForMaxF=\",crt_c )\n",
    "        #if crt_c in possible_answers:\n",
    "        #    print(\"FOUND IN LIST \", crt_c)\n",
    "        if F1 > maxF1:\n",
    "            maxF1 = F1\n",
    "            cForMaxF = crt_c\n",
    "    if crt_c in possible_answers:\n",
    "        print( \"crt_c=\", crt_c, \" F1=\", F1 )\n",
    "print( \"maxF1=\", maxF1, \" cForMaxF=\",cForMaxF )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c12b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "crt_c= 0.12  F1= 0.8582375478927202\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "crt_c= 0.32  F1= 0.8582375478927202\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "crt_c= 0.52  F1= 0.8582375478927202\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "crt_c= 0.72  F1= 0.8582375478927202\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "0.8549618320610687 0.8615384615384616\n",
      "maxF1= 0.8582375478927202  cForMaxF= 0.01\n"
     ]
    }
   ],
   "source": [
    "# Variant using Alexey's functions\n",
    "\n",
    "possible_answers = [0.12, 0.32, 0.52, 0.72]\n",
    "maxF1 = 0\n",
    "cForMaxF = 0\n",
    "treshhold = 0.5\n",
    "for crt_c in np.arange(0.01,1.0,0.01):\n",
    "    # avoid the rounding error\n",
    "    crt_c = round(crt_c,2) + 0.0\n",
    "    \n",
    "    dv, model = train(df_train, y_train, C=crt_c)\n",
    "    y_val_pred = predict(df_val, dv, model)\n",
    "    \n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "\n",
    "    predict_positive = (y_pred >= treshhold)\n",
    "    predict_negative = (y_pred < treshhold)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall =  tp / (tp + fn)\n",
    "    \n",
    "    #precision = precision_score(y_val, y_val_pred >= 0.5, average='weighted')\n",
    "    #recall = recall_score(y_val, y_val_pred >= 0.5, average='weighted')\n",
    "    \n",
    "    precissionList.append(precision)\n",
    "    recallList.append(recall)\n",
    "    \n",
    "    print(precision, recall)\n",
    "    #round_val = 3\n",
    "    #precision = round( precision, round_val )\n",
    "    #recall = round( precision, round_val )\n",
    "    \n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    if F1 >= maxF1:\n",
    "        #print( \"Found new max F1; maxF1=\", F1, \" cForMaxF=\",crt_c )\n",
    "        #if crt_c in possible_answers:\n",
    "        #    print(\"FOUND IN LIST \", crt_c)\n",
    "        if F1 > maxF1:\n",
    "            maxF1 = F1\n",
    "            cForMaxF = crt_c\n",
    "    if crt_c in possible_answers:\n",
    "        print( \"crt_c=\", crt_c, \" F1=\", F1 )\n",
    "print( \"maxF1=\", maxF1, \" cForMaxF=\",cForMaxF )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c261801",
   "metadata": {},
   "source": [
    "Question 5: 5-Fold CV\n",
    "\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    Iterate over different folds of df_full_train\n",
    "    Split the data into train and validation\n",
    "    Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard devidation of the scores across different folds?\n",
    "\n",
    "    0.003\n",
    "    0.030\n",
    "    0.090\n",
    "    0.140\n",
    "    \n",
    "ANSWER: 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddbcb0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979 +- 0.002\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "C=1.0\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train[ 'above_average' ]\n",
    "    y_val = df_val[ 'above_average' ]\n",
    "\n",
    "    del df_train[ 'above_average' ]\n",
    "    del df_val[ 'above_average' ]\n",
    "\n",
    "    \n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a2c34",
   "metadata": {},
   "source": [
    "Question 6: Hyperparemeter Tuning\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "    Iterate over the following C values: [0.01, 0.1, 0.5, 10]\n",
    "    Initialize KFold with the same parameters as previously\n",
    "    Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "    0.01\n",
    "    0.1\n",
    "    0.5\n",
    "    10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C.\n",
    "\n",
    "ANSWER: C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec78733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 0.952 +- 0.003\n",
      "C=0.1 0.972 +- 0.002\n",
      "C=0.5 0.977 +- 0.002\n",
      "C=10 0.981 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "cList = [0.01, 0.1, 0.5, 10]\n",
    "\n",
    "for C in cList:\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train[ 'above_average' ]\n",
    "        y_val = df_val[ 'above_average' ]\n",
    "\n",
    "        del df_train[ 'above_average' ]\n",
    "        del df_val[ 'above_average' ]\n",
    "\n",
    "    \n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e10466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
